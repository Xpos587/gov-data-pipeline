from __future__ import annotations

import re
import base64
import json
import logging
import asyncio
import unicodedata
from io import BytesIO
from typing import Dict, List, Optional, Any, cast

from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion
from openai.types.chat import ChatCompletionMessageParam
from openai.types.chat import completion_create_params
from openai import RateLimitError, AuthenticationError, APIError
from pydantic import BaseModel, Field
from utils.settings import settings
import polars as pl
from PIL import Image

logger = logging.getLogger(__name__)

IMAGE_MODEL = "llama-3.2-11b-vision-preview"
BRAND_MODEL = "llama-3.1-8b-instant"
CORRECT_MODEL = "llama-3.1-8b-instant"


class BrandRecognitionResponse(BaseModel):
    english_samples: List[str] = Field(
        ..., description="Samples of brand names in English (max 6)."
    )
    russian_samples: List[str] = Field(
        ..., description="Samples of brand names in Russian (max 6)."
    )
    original_text: str = Field(
        ..., description="Original text where the brand is searched for."
    )


class RowCorrectionResponse(BaseModel):
    corrected_row: Dict[str, str] = Field(
        ..., description="Corrected row (column -> value dictionary)."
    )


def is_excluded(row_text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ "–∏—Å–∫–ª—é—á—ë–Ω" –∏–ª–∏ "–∏—Å–∫–ª—é—á–µ–Ω".
    –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä –∏ –ø—Ä–æ–±–µ–ª—ã.
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç: —É–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã, –∑–∞–º–µ–Ω—è–µ–º "—ë" –Ω–∞ "–µ", –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    normalized_text = re.sub(r"\s+", "", row_text)  # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    normalized_text = normalized_text.casefold().replace("—ë", "–µ")
    return "–∏—Å–∫–ª—é—á–µ–Ω" in normalized_text


async def image_to_base64(image_data: bytes) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64-—Å—Ç—Ä–æ–∫—É —Ñ–æ—Ä–º–∞—Ç–∞ data:image/png;base64,....
    """
    buf = BytesIO(image_data)
    try:
        img = Image.open(buf)
        if img.format != "PNG":
            out_buf = BytesIO()
            img.save(out_buf, format="PNG")
            image_data = out_buf.getvalue()
    except Exception as exc:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {exc}")
        return ""

    encoded = base64.b64encode(image_data).decode("utf-8")
    return f"data:image/png;base64,{encoded}"


def clean_messages(
    messages: List[ChatCompletionMessageParam],
) -> List[ChatCompletionMessageParam]:
    """
    –û—á–∏—â–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö Unicode-—Å–∏–º–≤–æ–ª–æ–≤.

    –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª—é—á–∞ "content" ‚Äî —Å—Ç—Ä–æ–∫–∞, —É–¥–∞–ª—è—é—Ç—Å—è –≤—Å–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è –ø—Ä–æ–±–µ–ª—ã.
    –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî —Å–ø–∏—Å–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è GPT Vision), —Ç–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞,
    –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º "text", —Ç–∞–∫–∂–µ –æ—á–∏—â–∞–µ—Ç—Å—è —Ç–µ–∫—Å—Ç.
    """
    cleaned: List[ChatCompletionMessageParam] = []

    for msg in messages:
        # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è
        new_msg: Dict[str, Any] = dict(msg)

        content: Any = new_msg.get("content", None)

        if isinstance(content, str):
            # –£–¥–∞–ª—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–∫–∞—Ç–µ–≥–æ—Ä–∏—è "C")
            cleaned_text = "".join(
                ch for ch in content if unicodedata.category(ch)[0] != "C"
            )
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            cleaned_text = re.sub(r"\s+", " ", cleaned_text).strip()
            new_msg["content"] = cleaned_text

        elif isinstance(content, list):
            # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ content ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            content_list: List[Any] = cast(List[Any], content)
            new_content: List[Any] = []
            for item in content_list:
                if isinstance(item, dict) and "text" in item:
                    # –ü—Ä–∏–≤–æ–¥–∏–º item –∫ dict[str, Any]
                    item_dict: Dict[str, Any] = cast(Dict[str, Any], item)
                    text_val: str = str(item_dict.get("text", ""))

                    # –£–¥–∞–ª—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
                    text_val = "".join(
                        ch for ch in text_val if unicodedata.category(ch)[0] != "C"
                    )
                    text_val = re.sub(r"\s+", " ", text_val).strip()

                    # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ "text"
                    new_item: Dict[str, Any] = {}
                    for key_item, val_item in item_dict.items():
                        new_item[key_item] = val_item
                    new_item["text"] = text_val
                    new_content.append(new_item)
                else:
                    new_content.append(item)

            new_msg["content"] = new_content

        cleaned.append(cast(ChatCompletionMessageParam, new_msg))

    return cleaned


async def call_openai(
    client: AsyncOpenAI,
    model: str,
    messages: List[ChatCompletionMessageParam],
    max_retries: int = 5,
    initial_delay: float = 2,
    temperature: float = 0.1,
    max_tokens: int = 64,
    response_format: completion_create_params.ResponseFormat = {"type": "text"},
) -> ChatCompletion:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI ChatCompletion —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏
    RateLimitError (429), AuthenticationError (401) –∏ –¥—Ä—É–≥–∏—Ö API-–æ—à–∏–±–∫–∞—Ö.

    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤,
    —á—Ç–æ–±—ã –≤ GPT –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–æ–ø–∞–¥–∞–ª–∏ "–≥—Ä—è–∑–Ω—ã–µ" Unicode-—Å–∏–º–≤–æ–ª—ã.

    Args:
        client (AsyncOpenAI): –ö–ª–∏–µ–Ω—Ç OpenAI.
        model (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.
        messages (List[ChatCompletionMessageParam]): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏.
        max_retries (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫.
        initial_delay (float): –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π.
        temperature (float): –ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã.
        max_tokens (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ.
        response_format (completion_create_params.ResponseFormat): –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞.

    Returns:
        ChatCompletion: –û—Ç–≤–µ—Ç –æ—Ç OpenAI Chat API.
    """
    # –û—á–∏—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∑–∞–ø—Ä–æ—Å–∞
    messages = clean_messages(messages)

    delay: float = initial_delay
    for attempt in range(1, max_retries + 1):
        try:
            response: ChatCompletion = await client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                response_format=response_format,
            )

            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã
            usage = response.usage
            if usage:
                logger.info(
                    f"[–ú–æ–¥–µ–ª—å {model}] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: "
                    f"prompt_tokens={usage.prompt_tokens}, "
                    f"completion_tokens={usage.completion_tokens}, "
                    f"total_tokens={usage.total_tokens}"
                )

            return response
        except (RateLimitError, AuthenticationError) as err:
            if attempt < max_retries:
                logger.warning(
                    f"–û—à–∏–±–∫–∞ {err.__class__.__name__}. –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay} —Å–µ–∫..."
                )
                await asyncio.sleep(delay)
                delay *= 2
            else:
                logger.error("–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø–æ–≤—Ç–æ—Ä–æ–≤!")
                raise
        except APIError as err:
            logger.error(f"API –û—à–∏–±–∫–∞: {err}. –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}.")
            if attempt < max_retries:
                await asyncio.sleep(delay)
                delay *= 2
            else:
                logger.error("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ API.")
                raise

    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.")


async def process_table(
    df: pl.DataFrame,
    brand_column: str,
    description_column: Optional[str] = None,
    correction: bool = False,
) -> pl.DataFrame:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç DataFrame, —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –±—Ä–µ–Ω–¥—ã –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É.

    1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ "–∏—Å–∫–ª—é—á—ë–Ω"/"–∏—Å–∫–ª—é—á–µ–Ω".
       –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç ‚Äî –ø–æ–º–µ—á–∞–µ—Ç —Å—Ç—Ä–æ–∫—É, –¥–æ–±–∞–≤–ª—è—è –ø–æ–ª–µ "–ò—Å–∫–ª—é—á–µ–Ω–æ = '–î–∞'" –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –¥–∞–ª—å–Ω–µ–π—à—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.

    2. –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –∏—Å–∫–ª—é—á–µ–Ω–∞, –≤—ã–∑—ã–≤–∞–µ—Ç `recognize_brand` –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ —Å –±—Ä–µ–Ω–¥–æ–º –∏, –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, —Å—Ç–æ–ª–±—Ü–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º.
       –ó–∞–º–µ–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –Ω–∞ (original_text + english_samples + russian_samples).

    3. –í—ã–∑—ã–≤–∞–µ—Ç `correct_row` –¥–ª—è –∏—Ç–æ–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

    Args:
        df (pl.DataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏.
        brand_column (str): –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞, —Å–æ–¥–µ—Ä–∂–∞—â–µ–≥–æ —Ç–æ—Ä–≥–æ–≤—É—é –º–∞—Ä–∫—É.
        description_column (Optional[str]): –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ñ–∏—Ä–º—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.

    Returns:
        pl.DataFrame: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –ø–æ–ª–µ–º '–ò—Å–∫–ª—é—á–µ–Ω–æ' –∏/–∏–ª–∏ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
    """
    client = AsyncOpenAI(
        api_key=settings.openai.api_key.get_secret_value(),
        base_url=settings.openai.base_url,
    )

    brand_system_prompt = (
        "Analyze the input text to identify brand names, product names, or any potential trademark-like terms. "
        "Provide multiple variations of the identified names, including:\n"
        "- The most likely correct spelling\n"
        "- Russian transliteration\n"
        "- English transliteration\n"
        "- Common alternative spellings\n"
        "- Additional variations if uncertain\n"
        "\n"
        "**Guidelines:**\n"
        "- If the input contains a recognizable brand or product name, extract it.\n"
        "- If not 100% sure, still include possible brand-like terms.\n"
        "- Always return multiple variations (max 6 per language).\n"
        "- Ensure both Russian and English versions are included.\n"
        "- Avoid empty arrays‚Äîif unsure, provide the most plausible brand-like terms.\n"
        "- Normalize spacing and remove unnecessary formatting.\n"
        "- Strictly return JSON in the required schema with no extra text.\n"
        "\n"
        "**Example responses:**\n"
        "\n"
        "For input: '–ù–∞–π–∫–∏'\n"
        "{\n"
        '    "original_text": "–ù–∞–π–∫–∏",\n'
        '    "english_samples": ["Nike", "Naiki", "NIKE", "Naykee"],\n'
        '    "russian_samples": ["–ù–∞–π–∫–∏", "–ù–∞–π–∫"]\n'
        "}\n"
        "\n"
        "For input: '–ê–¥–∏–¥–∞—Å —Å–ø–æ—Ä—Ç'\n"
        "{\n"
        '    "original_text": "–ê–¥–∏–¥–∞—Å —Å–ø–æ—Ä—Ç",\n'
        '    "english_samples": ["Adidas", "Adidas Sport"],\n'
        '    "russian_samples": ["–ê–¥–∏–¥–∞—Å", "–ê–¥–∏–¥–∞—Å –°–ø–æ—Ä—Ç"]\n'
        "}\n"
        "\n"
        "For input: 'Samsung Electronics Co., Ltd.'\n"
        "{\n"
        '    "original_text": "Samsung Electronics Co., Ltd.",\n'
        '    "english_samples": ["Samsung", "Samsung Electronics"],\n'
        '    "russian_samples": ["–°–∞–º—Å—É–Ω–≥", "–°–∞–º—Å—É–Ω–≥ –≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—Å"]\n'
        "}\n"
        "\n"
        "For input: '–û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞'\n"
        "{\n"
        '    "original_text": "–û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞",\n'
        '    "english_samples": ["Roga i Kopyta LLC"],\n'
        '    "russian_samples": ["–†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞"]\n'
        "}\n"
        "\n"
        "Respond strictly in JSON format following the provided schema. "
        f"You MUST return ONLY valid JSON with the following schema:\n"
        f"{json.dumps(BrandRecognitionResponse.model_json_schema(), indent=2)}\n"
        "No markdown fences. No extra text. Strictly output valid JSON or return an empty JSON object."
    )

    row_system_prompt: str = (
        "Correct the table row. Respond strictly in JSON format with the key 'corrected_row' following the provided schema:\n"
        f"{json.dumps(RowCorrectionResponse.model_json_schema(), indent=2)}"
    )

    async def recognize_image(base64_image: str) -> str:
        """
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GPT Vision –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        """
        response = await call_openai(
            client,
            model=IMAGE_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": (
                                "You must return ONLY the text found in the image."
                                "No descriptions, no explanations, no formatting."
                                "Just the raw text."
                            ),
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": base64_image},
                        },
                    ],
                },
            ],
            temperature=0.1,
            max_tokens=64,
        )
        return response.choices[0].message.content or ""

    async def recognize_brand(
        text: str, description: Optional[str] = None, row_idx: int = 0
    ) -> BrandRecognitionResponse:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –±—Ä–µ–Ω–¥, –≤–æ–∑–≤—Ä–∞—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É BrandRecognitionResponse.
        –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞ base64-—Å—Ç—Ä–æ–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –∏ –∑–∞–º–µ–Ω—è–µ—Ç –µ—ë –Ω–∞ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
        –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ description_column —É–∫–∞–∑–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–≥–æ —Ç–µ–∫—Å—Ç –∫ —Ç–µ–∫—Å—Ç—É –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
        """
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ –≤–æ–∑–º–æ–∂–Ω—É—é —Å—Ç—Ä–æ–∫—É data:image/png;base64,....
        pattern = r"data:image/png;base64,[A-Za-z0-9+/=]+"
        match = re.search(pattern, text)
        if match:
            base64_str = match.group(0)
            recognized = await recognize_image(base64_str)
            # –ó–∞–º–µ–Ω—è–µ–º base64 –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π
            text = text.replace(base64_str, recognized)

        # –ï—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
        if description:
            text = f"{text}. Description: {description}"

        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Ü–∏—Ñ—Ä—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r"\d+", "", text)
        text = re.sub(r"\s+", " ", text).strip()

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è GPT
        max_length = 2000
        if len(text) > max_length:
            text = text[:max_length] + "..."

        logger.info(f"–ó–∞–ø—Ä–æ—Å (–°—Ç—Ä–æ–∫–∞ {row_idx}): {text}")

        response = await call_openai(
            client,
            model=BRAND_MODEL,
            messages=[
                {"role": "system", "content": brand_system_prompt},
                {"role": "user", "content": text},
            ],
            temperature=0.3,
            max_tokens=256,
            response_format={"type": "json_object"},
        )

        raw_text: str = response.choices[0].message.content or ""
        logger.info(f"–û—Ç–≤–µ—Ç (–°—Ç—Ä–æ–∫–∞ {row_idx}): {raw_text}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON-–æ—Ç–≤–µ—Ç
        try:
            data = json.loads(raw_text)

            if "english_samples" not in data:
                logger.warning(
                    f"[–°—Ç—Ä–æ–∫–∞ {row_idx}] 'english_samples' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ!"
                )
                data["english_samples"] = []
            if "russian_samples" not in data:
                logger.warning(
                    f"[–°—Ç—Ä–æ–∫–∞ {row_idx}] 'russian_samples' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ!"
                )
                data["russian_samples"] = []

            return BrandRecognitionResponse.model_validate(data)

        except Exception as e:
            logger.error(f"[–°—Ç—Ä–æ–∫–∞ {row_idx}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON-–æ—Ç–≤–µ—Ç–∞: {e}")
            logger.error(f"[–°—Ç—Ä–æ–∫–∞ {row_idx}] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç: {raw_text}")
            return BrandRecognitionResponse(
                english_samples=[], russian_samples=[], original_text=text
            )

    async def correct_row(row_data: Dict[str, Optional[str]]) -> RowCorrectionResponse:
        """
        –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É, –≤–æ–∑–≤—Ä–∞—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É RowCorrectionResponse.
        """
        logger.debug(f"–ó–∞–ø—Ä–æ—Å: {json.dumps(row_data, ensure_ascii=False)}")

        response = await call_openai(
            client,
            model=CORRECT_MODEL,
            messages=[
                {"role": "system", "content": row_system_prompt},
                {
                    "role": "user",
                    "content": json.dumps({"row": row_data}, ensure_ascii=False),
                },
            ],
            temperature=0.2,
            max_tokens=384,
            response_format={"type": "json_object"},
        )

        raw_text: str = response.choices[0].message.content or ""
        logger.debug(f"–û—Ç–≤–µ—Ç: {raw_text}")

        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –≤ –º–æ–¥–µ–ª—å RowCorrectionResponse
        corrected_resp = RowCorrectionResponse.model_validate_json(raw_text)

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è —Å—Ç—Ä–æ–∫–∞–º–∏
        for k, v in corrected_resp.corrected_row.items():
            corrected_resp.corrected_row[k] = v

        return corrected_resp

    processed_rows: List[Dict[str, str]] = []

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ DataFrame
    for idx, row in enumerate(df.iter_rows(named=True), start=1):
        row_dict: Dict[str, Optional[str]] = dict(row)
        logger.info(f"=== –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É {idx}: {row_dict}")

        # 1) –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–∫–ª—é—á–µ–Ω–∞ –ª–∏ –¢–ú (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É)
        combined_text = " ".join(
            str(val) for val in row_dict.values() if val is not None
        )
        if is_excluded(combined_text):
            logger.info(f"[–°—Ç—Ä–æ–∫–∞ {idx}] –ò—Å–∫–ª—é—á–µ–Ω–∞ (—Å–æ–¥–µ—Ä–∂–∏—Ç '–∏—Å–∫–ª—é—á—ë–Ω'). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            row_dict["–ò—Å–∫–ª—é—á–µ–Ω–æ"] = "–î–∞"
            processed_rows.append({k: (v or "") for k, v in row_dict.items()})
            continue  # üöÄ –¢–µ–ø–µ—Ä—å —Å—Ç—Ä–æ–∫–∞ —Ç–æ—á–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –≤—ã–∑–æ–≤–∞ GPT!

        # 2) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–æ–ª–±–µ—Ü brand_column (–µ—Å–ª–∏ –Ω–µ –∏—Å–∫–ª—é—á–µ–Ω–æ)
        brand_val = row_dict.get(brand_column)
        description_val = (
            row_dict.get(description_column) if description_column else None
        )

        if isinstance(brand_val, str) and brand_val.strip():
            brand_resp = await recognize_brand(brand_val, description_val, row_idx=idx)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            combined_brand_info = " ".join(
                [
                    brand_resp.original_text,
                    ", ".join(brand_resp.english_samples),
                    ", ".join(brand_resp.russian_samples),
                ]
            ).strip()
            row_dict[brand_column] = combined_brand_info

        # 3) –î–æ–±–∞–≤–ª—è–µ–º '–ò—Å–∫–ª—é—á–µ–Ω–æ' = '–ù–µ—Ç'
        row_dict["–ò—Å–∫–ª—é—á–µ–Ω–æ"] = "–ù–µ—Ç"

        # 4) –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Å—Ç—Ä–æ–∫–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        if correction:
            try:
                corrected_resp = await correct_row(row_dict)
                processed_rows.append(corrected_resp.corrected_row)
            except Exception as e:
                logger.error(f"[–°—Ç—Ä–æ–∫–∞ {idx}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ: {e}")
                logger.error(f"[–°—Ç—Ä–æ–∫–∞ {idx}] –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π: {row_dict}")
                processed_rows.append({k: str(v or "") for k, v in row_dict.items()})
        else:
            processed_rows.append({k: str(v or "") for k, v in row_dict.items()})

    return pl.DataFrame(processed_rows)
